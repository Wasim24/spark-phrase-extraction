package spark.phrase.phraser

import scala.collection.mutable

/**
  * Config params supported are listed below:
  * - `minCount:` minimum number of times a ngram should appear to get added into corpus.
  * - `threshold:` threshold on score generated by scorer. Its used to prune vocab, when it learns more than maxVocabSize.
  * - `maxVocabSize:` maximun default of 4,00,000 corpus is learnt
  * - `delimiter:` used to concat ngrams identified and replace in a sentence. Example Sentence: `San Francisco is a beautiful city`. After ngrams identification: `San_Francisco is a beautiful_city`. Tokens are concatenated with default "_" delimiter.
  * - `progressPer:` While training, how frequently to show progress
  * - `commonWords:` Used to concate common words occuring in between one gram's ex: `bank_of_america` is identified as a bigram provided `of` is set as a common word.
*/
trait PhrasesConfig extends Serializable {

  val minCount: Int
  val threshold: Float
  val maxVocabSize: Int
  val delimiter: String
  val progressPer: Int
  var commonWords: Option[mutable.HashSet[String]]

  def isCommonWord(word: String): Boolean = {
    word != null && word != "" && commonWords.isDefined && commonWords.get.contains(word)
  }
}

case class SimplePhrasesConfig(
                                minCount:Int = 5,
                                threshold: Float = 10.0F,
                                maxVocabSize: Int = 40000000,
                                delimiter: String = "_",
                                progressPer: Int =50,
                                var commonWords: Option[mutable.HashSet[String]] = None) extends PhrasesConfig

object DefaultPhrasesConfig extends SimplePhrasesConfig()//commonWords = Some(Util.loadStopWords()))
